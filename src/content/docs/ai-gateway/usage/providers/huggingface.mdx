---
title: HuggingFace
pcx_content_type: get-started
---

import { Tabs, TabItem } from "~/components";

[HuggingFace](https://huggingface.co/) helps users build, deploy and train machine learning models.

## Endpoint

```txt
https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/huggingface
```

## URL structure

When making requests to HuggingFace Inference API, replace `https://api-inference.huggingface.co/models/` in the URL you're currently using with `https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/huggingface`. Note that the model you're trying to access should come right after, for example `https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/huggingface/bigcode/starcoder`.

## Prerequisites

When making requests to HuggingFace, ensure you have the following:

- Your AI Gateway Account ID.
- Your AI Gateway gateway name.
- An active HuggingFace API token.
- The name of the HuggingFace model you want to use.

## Examples

### cURL

```bash title="Request"
curl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/huggingface/bigcode/starcoder \
  --header 'Authorization: Bearer {hf_api_token}' \
  --header 'Content-Type: application/json' \
  --data '{
    "inputs": "console.log"
}'
```

### Use HuggingFace.js library with JavaScript

If you are using the HuggingFace.js library, you can set your inference endpoint like this:

<Tabs syncKey="sdk">
<TabItem label="Javascript" icon="seti:javascript">

```js title="JavaScript"
import { HfInferenceEndpoint } from "@huggingface/inference";

const accountId = "{account_id}";
const gatewayId = "{gateway_id}";
const model = "gpt2";
const baseURL = `https://gateway.ai.cloudflare.com/v1/${accountId}/${gatewayId}/huggingface/${model}`;
const apiToken = env.HF_API_TOKEN;

const hf = new HfInferenceEndpoint(baseURL, apiToken);
```

</TabItem>
<TabItem label="Javascript (Workers)" icon="seti:javascript">

:::note
For detailed information about using the AI Gateway SDK in Workers, refer to [Using AI Gateway in Workers](/ai-gateway/usage/workers/).
:::

```js title="JavaScript"
import { HfInferenceEndpoint } from "@huggingface/inference";
import { useAIGateway, ProviderAuth } from "@cloudflare/ai-gateway";

export default {
	async fetch(request, env) {
		useAIGateway({ binding: env.AI, gateway: "test-gateway" });

		// Use ProviderAuth.storedKey() for BYOK or pass an authorization token directly (e.g., env.HF_API_TOKEN)
		const auth = ProviderAuth.storedKey();
		const model = "gpt2";
		const baseURL = `https://api-inference.huggingface.co/models/${model}`;

		const hf = new HfInferenceEndpoint(baseURL, auth);

		return Response.json({ configured: true });
	},
};
```

</TabItem>
</Tabs>
