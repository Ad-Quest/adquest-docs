---
title: OpenRouter
pcx_content_type: get-started
---

import { Tabs, TabItem } from "~/components";

[OpenRouter](https://openrouter.ai/) is a platform that provides a unified interface for accessing and using large language models (LLMs).

## Endpoint

```txt
https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openrouter
```

## URL structure

When making requests to [OpenRouter](https://openrouter.ai/), replace `https://openrouter.ai/api/v1/chat/completions` in the URL you are currently using with `https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openrouter/chat/completions`.

## Prerequisites

When making requests to OpenRouter, ensure you have the following:

- Your AI Gateway Account ID.
- Your AI Gateway gateway name.
- An active OpenRouter API token or a token from the original model provider.
- The name of the OpenRouter model you want to use.

## Examples

### cURL

```bash title="Request"
curl -X POST https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openrouter/v1/chat/completions \
 --header 'content-type: application/json' \
 --header 'Authorization: Bearer OPENROUTER_TOKEN' \
 --data '{
    "model": "openai/gpt-5-mini",
    "messages": [
        {
            "role": "user",
            "content": "What is Cloudflare?"
        }
    ]
}'

```

### Use OpenAI SDK with JavaScript

If you are using the OpenAI SDK with JavaScript, you can set your endpoint like this:

<Tabs syncKey="sdk">
<TabItem label="Javascript" icon="seti:javascript">

```js title="JavaScript"
import OpenAI from "openai";

const openai = new OpenAI({
	apiKey: env.OPENROUTER_TOKEN,
	baseURL:
		"https://gateway.ai.cloudflare.com/v1/ACCOUNT_TAG/GATEWAY/openrouter",
});

try {
	const chatCompletion = await openai.chat.completions.create({
		model: "openai/gpt-5-mini",
		messages: [{ role: "user", content: "What is Cloudflare?" }],
	});

	const response = chatCompletion.choices[0].message;

	return new Response(JSON.stringify(response));
} catch (e) {
	return new Response(e);
}
```

</TabItem>
<TabItem label="Javascript (Workers)" icon="seti:javascript">

:::note
For detailed information about using the AI Gateway SDK in Workers, refer to [Using AI Gateway in Workers](/ai-gateway/usage/workers/).
:::

```js title="JavaScript"
import OpenAI from "openai";
import { useAIGateway, ProviderAuth } from "@cloudflare/ai-gateway";

export default {
	async fetch(request, env) {
		useAIGateway({ binding: env.AI, gateway: "test-gateway" });

		// Use ProviderAuth.storedKey() for BYOK or pass an authorization token directly (e.g., env.OPENROUTER_API_KEY)
		const auth = ProviderAuth.storedKey();

		const openai = new OpenAI({
			apiKey: auth,
			baseURL: "https://openrouter.ai/api/v1",
		});

		try {
			const chatCompletion = await openai.chat.completions.create({
				model: "openai/gpt-5-mini",
				messages: [{ role: "user", content: "What is Cloudflare?" }],
			});

			const response = chatCompletion.choices[0].message;

			return new Response(JSON.stringify(response));
		} catch (e) {
			return new Response(e);
		}
	},
};
```

</TabItem>
</Tabs>
