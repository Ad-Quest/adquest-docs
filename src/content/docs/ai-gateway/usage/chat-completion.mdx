---
title: Unified API (OpenAI compat)
pcx_content_type: reference
tags:
  - AI
sidebar:
  order: 2
---

import {
	Details,
  Tabs,
  TabItem
} from "~/components";

Cloudflare's AI Gateway offers an OpenAI-compatible `/chat/completions` endpoint, enabling integration with multiple AI providers using a single URL. This feature simplifies the integration process, allowing for seamless switching between different models without significant code modifications.

## Endpoint URL

```txt
https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions
```

Replace `{account_id}` and `{gateway_id}` with your Cloudflare account and gateway IDs.

## Parameters

Switch providers by changing the `model` and `apiKey` parameters.

Specify the model using `{provider}/{model}` format. For example:

- `openai/gpt-5-mini`
- `google-ai-studio/gemini-2.5-flash`
- `anthropic/claude-sonnet-4-5`

## Examples

### OpenAI SDK

<Details header="With Key in Request">
<Tabs>
<TabItem label="With Authenticated Gateway">
```js title=""
import OpenAI from "openai";

const client = new OpenAI({
	apiKey: "YOUR_PROVIDER_API_KEY",
	defaultHeaders: {
		"cf-aig-authorization": `Bearer {cf_api_token}`,
	},
	baseURL:
		"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat",
});

// Use different providers by changing the model parameter
const response = await client.chat.completions.create({
	model: "google-ai-studio/gemini-2.5-flash", // or "openai/gpt-5-mini", "anthropic/claude-sonnet-4-5"
	messages: [{ role: "user", content: "Hello, world!" }],
});
```
</TabItem>
<TabItem label="Unauthenticated Gateway">
```js title=""
import OpenAI from "openai";

const client = new OpenAI({
	apiKey: "YOUR_PROVIDER_API_KEY",
	baseURL:
		"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat",
});

// Use different providers by changing the model parameter
const response = await client.chat.completions.create({
	model: "google-ai-studio/gemini-2.5-flash", // or "openai/gpt-5-mini", "anthropic/claude-sonnet-4-5"
	messages: [{ role: "user", content: "Hello, world!" }],
});
```
</TabItem>
</Tabs>
</Details>
<Details header="With Stored Keys (BYOK) / Unified Billing" open>
```js title="OpenAI JS SDK"
import OpenAI from "openai";

const client = new OpenAI({
	apiKey: "{cf_api_token}",
	baseURL:
		"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat",
});

// Ensure either your LLM Keys are stored with BYOK
// or Unified Billing has credits
const response = await client.chat.completions.create({
	// Use different providers by changing the model parameter
	model: "google-ai-studio/gemini-2.5-flash", // or "openai/gpt-5-mini"
	messages: [{ role: "user", content: "Hello, world!" }],
});
```
</Details>

### cURL


<Details header="With Key in Request">
<Tabs>
<TabItem label="With Authenticated Gateway">
```bash title=""
curl -X POST https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions \
  --header 'Authorization: Bearer {GOOGLE_GENERATIVE_AI_API_KEY}' \
  --header 'cf-aig-authorization: Bearer {CF_AIG_TOKEN}' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "google-ai-studio/gemini-2.5-flash",
    "messages": [
      {
        "role": "user",
        "content": "What is Cloudflare?"
      }
    ]
  }'
```
</TabItem>
<TabItem label="Unauthenticated Gateway">
```bash title=""
curl -X POST https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions \
  --header 'Authorization: Bearer {GOOGLE_GENERATIVE_AI_API_KEY}' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "google-ai-studio/gemini-2.5-flash",
    "messages": [
      {
        "role": "user",
        "content": "What is Cloudflare?"
      }
    ]
  }'
```
</TabItem>
</Tabs>
</Details>
<Details header="With Stored Keys (BYOK) / Unified Billing" open>
```bash title=""
curl -X POST https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions \
  --header 'cf-aig-authorization: Bearer {CF_AIG_TOKEN}' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "google-ai-studio/gemini-2.5-flash",
    "messages": [
      {
        "role": "user",
        "content": "What is Cloudflare?"
      }
    ]
  }'
```
</Details>

## Supported Providers

The OpenAI-compatible endpoint supports models from the following providers:

- [Anthropic](/ai-gateway/usage/providers/anthropic/)
- [OpenAI](/ai-gateway/usage/providers/openai/)
- [Groq](/ai-gateway/usage/providers/groq/)
- [Mistral](/ai-gateway/usage/providers/mistral/)
- [Cohere](/ai-gateway/usage/providers/cohere/)
- [Perplexity](/ai-gateway/usage/providers/perplexity/)
- [Workers AI](/ai-gateway/usage/providers/workersai/)
- [Google-AI-Studio](/ai-gateway/usage/providers/google-ai-studio/)
- [Google Vertex AI](/ai-gateway/usage/providers/vertex/)
- [xAI](/ai-gateway/usage/providers/grok/)
- [DeepSeek](/ai-gateway/usage/providers/deepseek/)
- [Cerebras](/ai-gateway/usage/providers/cerebras/)
- [Baseten](/ai-gateway/usage/providers/baseten/)
- [Parallel](/ai-gateway/usage/providers/parallel/)
