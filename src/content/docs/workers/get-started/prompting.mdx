---
title: Prompting
pcx_content_type: concept
description: Build Workers apps with AI prompts and MCP servers.
tags:
  - AI
  - LLM
sidebar:
  order: 3
---

import { Code } from "@astrojs/starlight/components";
import BasePrompt from "~/content/partials/prompts/base-prompt.txt?raw";

You can create Workers applications from simple prompts in your favorite agent or editor, including Cursor, Windsurf, VS Code, Claude Code, Codex, and OpenCode.

## Teach your agent about Workers

Connect the [`cloudflare-docs`](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/docs-vectorize) MCP (Model Context Protocol) server to teach your agent about Workers. Add the server URL `https://docs.mcp.cloudflare.com/mcp` to your agent configuration ([learn more](/agents/model-context-protocol/mcp-servers-for-cloudflare/)).

You can also connect the [`cloudflare-observability`](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/workers-observability) MCP server (`https://observability.mcp.cloudflare.com/mcp`). This helps your agent check logs, look for exceptions, and automatically fix issues.

## Example prompts

```txt
Create a Cloudflare Workers application that serves as a backend API server.
```

```txt
Show me how to use Hyperdrive to connect my Worker to an existing Postgres database.
```

```txt
Create an AI chat Agent using the Cloudflare Agents SDK that responds to user messages and maintains conversation history.
```

```txt
Build a WebSocket-based pub/sub application using Durable Objects Hibernation APIs, where the server allows me to POST to /send-message with {topic: "foo", message: "bar"} and delivers that message to any connected client listening to that topic.
```

```txt
Build an image upload application using R2 pre-signed URLs that allows users to securely upload images directly to object storage without exposing bucket credentials.
```

## Use a prompt

You can use the base prompt below to provide your AI tool with context about Workers APIs and best practices.

1. Use the click-to-copy button at the top right of the code block below to copy the full prompt to your clipboard.
2. Paste into your AI tool of choice (for example OpenAI's ChatGPT or Anthropic's Claude).
3. Enter your part of the prompt at the end between the `<user_prompt>` and `</user_prompt>` tags.

Base prompt:

<Code code={BasePrompt} collapse={"30-10000"} lang="md" />

The prompt above adopts several best practices, including:

- Using `<xml>` tags to structure the prompt
- API and usage examples for products and use cases
- Guidance on how to generate configuration (for example, `wrangler.jsonc`) as part of the model's response
- Recommendations on Cloudflare products to use for specific storage or state needs

### Additional uses

You can use the prompt in several ways:

- Within the user context window, with your own user prompt inserted between the `<user_prompt>` tags (**easiest**)
- As the `system` prompt for models that support system prompts
- Adding it to the prompt library or file context in your preferred IDE:
  - Cursor: add the prompt to [your Project Rules](https://docs.cursor.com/context/rules-for-ai)
  - Zed: use [the `/file` command](https://zed.dev/docs/assistant/assistant-panel) to add the prompt to the Assistant context
  - Windsurf: use [the `@-mention` command](https://docs.codeium.com/chat/overview) to include a file containing the prompt to your Chat
  - Claude Code: add the prompt to your `CLAUDE.md` configuration after running `/init` to include best practices to a Workers project
  - GitHub Copilot: create the [`.github/copilot-instructions.md`](https://docs.github.com/en/copilot/customizing-copilot/adding-repository-custom-instructions-for-github-copilot) file at the root of your project and add the prompt

:::note

The prompts here are examples and should be adapted to your specific use case.

Depending on the model and user prompt, it may generate invalid code, configuration, or other errors. Review and test the generated code before deploying it.

:::

## Use docs in your editor

AI-enabled editors, including Cursor and Windsurf, can index documentation. Cursor includes the Cloudflare Developer Docs by default: you can use the [`@Docs`](https://cursor.com/docs/context/mentions#docs) command.

In other editors, such as Zed or Windsurf, you can paste in URLs to add to your context. Use the _Copy Page_ button to paste in Cloudflare docs directly, or fetch docs for each product by appending `llms-full.txt` to the root URL. For example, `https://developers.cloudflare.com/agents/llms-full.txt` or `https://developers.cloudflare.com/workflows/llms-full.txt`.

You can combine these with the Workers system prompt on this page to improve your editor or agent's understanding of the Workers APIs.

## Additional resources

To get the most out of AI models and tools, review the following guides on prompt engineering and structure:

- OpenAI's [prompt engineering](https://platform.openai.com/docs/guides/prompt-engineering) guide and [best practices](https://platform.openai.com/docs/guides/reasoning-best-practices) for using reasoning models.
- The [prompt engineering](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview) guide from Anthropic.
- Google's [quick start guide](https://services.google.com/fh/files/misc/gemini-for-google-workspace-prompting-guide-101.pdf) for writing effective prompts.
- Meta's [prompting documentation](https://www.llama.com/docs/how-to-guides/prompting/) for their Llama model family.
- GitHub's guide for [prompt engineering](https://docs.github.com/en/copilot/using-github-copilot/copilot-chat/prompt-engineering-for-copilot-chat) when using Copilot Chat.
